---
title: "Documentation"
permalink: /docs/
sidebar:
  title: "Home"
  nav: sidebar-docs  # See /docs/_data/navigation.yml
---

If you want a simple installation, please take a look at the [`WebLINX` Huggingface Dataset](https://huggingface.co/datasets/McGill-NLP/WebLINX) -- it will show you how to download the dataset and use it with the `datasets` library.

If you want to work with the full data (containing raw files, which require more complex processing), you will find that a specialized library will be helpful. 

In this page, you can find documentation about the `WebLINX` Python library we developed for this purpose.


## Installation

To install the library, you can use pip:

```bash
pip install weblinx
```

## Prerequisites

The dataset is quite large, so you might only be interested in a subset of the data. Thus, the easiest way to download the dataset is the use the `huggingface_hub` library:

```bash
# 1. Install the library
pip install huggingface_hub[cli]
```

Now, you can download the dataset:

```python
from huggingface_hub import snapshot_download

patterns = ["*.json"]
# Other options: 
# patterns = ["*.json", "*.html", "*.png", "*.mp4"]

# Download a subset of the dataset, or...
snapshot_download(
    repo_id="McGill-NLP/WebLINX-full", repo_type="dataset", local_dir="./wl_data", allow_patterns=patterns
)

# ... download the entire dataset
snapshot_download(
    repo_id="McGill-NLP/WebLINX-full", repo_type="dataset", local_dir="./wl_data"
)
```

## Using the WebLINX library

Now that you have the dataset, you can use the `weblinx` library to process the full data:

```python
from pathlib import Path
import weblinx as wl


wl_dir = Path("./wl_data")
split_path = wl_dir / "splits.json"

# Load the name of the demonstrations in the training split
demo_names = wl.utils.load_demo_names_in_split(split_path, split='train') 
# or 'valid' or 'indomain'

# Load the demonstrations
demos = [wl.Demonstration(name, base_dir=wl_dir) for name in names]

# Select a demo to work with
demo = demos[0]

# Load the Replay object, which contains the turns of the demonstration
replay = wl.Replay.from_demonstration(demo)

# Filter the turns to keep only the ones that are relevant for the task
turns = replay.filter_by_intents(
    "click", "textInput", "load", "say", "submit"
)

# Only keep the turns that have a good screenshot (i.e., the screenshot is not empty)
turns = wl.filter_turns(
    turns, lambda t: t.has_screenshot() and t.get_screenshot_status() == "good"
)

# Remove chat turns where the speaker is not the navigator (e.g. if you want to train a model to predict the next action)
turns = wl.filter_turns(
    turns,
    lambda turn: not (
        turn.type == "chat" and turn.get("speaker") != "navigator"
    ),
)
```

As you can see, the core `weblinx` has many useful functions to process the dataset, as well as various useful classes to represent the data (e.g. `Demonstration`, `Replay`, `Turn`). You can find more information about the library in the [documentation of the core WebLINX module]({{'/docs/core/' | relative_url }}).

You can also take a look at some useful `processing` functions in the [documentation of the processing module]({{'/docs/processing/' | relative_url }}), and some useful `utils` functions in the [documentation of the utils module]({{'/docs/utils/' | relative_url }}).


## Accessing element ranking scores

To access the elements and scores generated by the MiniLM-L6-dmr model, you can download them with:

```python
from huggingface_hub import snapshot_download
from weblinx.processing import load_candidate_elements

# Download the candidates generated by the MiniLM-L6-dmr model
snapshot_download(
    repo_id="McGill-NLP/WebLINX-full", 
    repo_type="dataset", 
    allow_patterns="candidates/*.jsonl", 
    local_dir="./wl_data/"
)

split = "train"  # or valid, test, test_geo, test_vis, test_web, test_cat 
candidates_path = f"./wl_data/candidates/{split}.jsonl"
# Access the candidates
candidates = load_candidate_elements(path=candidates_path)
```


## Examples for Training Action Model

First, make sure you have installed all the optional dependencies for the `weblinx` library:

```bash
pip install weblinx[all]
```

Then, you can use the `weblinx` library to build input records for training the model:

```python
from pathlib import Path
import weblinx as wl
from weblinx.prompt import (
    select_turns_and_candidates_for_prompts,
    build_input_records_from_selected_turns,
)
from weblinx.processing import load_candidate_elements

data_dir = Path("./wl_data")
split_path = data_dir / "splits.json"

# Load the name of the demonstrations in the training split
demo_names = wl.utils.load_demo_names_in_split(split_path, split='train')  # or 'valid' or 'test-iid'

# Load the demonstrations
demos = [wl.Demonstration(name, base_dir=data_dir) for name in names]

# Load candidates generated by DMR
candidates_path = 'path/to/candidates/<split>.json'
candidates = load_candidate_elements(path=candidates_path)

def build_prompt_records_custom(*args, **kwargs):
    # Your code here
    pass

def format_prompt_custom(*args, **kwargs):
    # Your code here
    pass

# Select turns and candidates for prompting from the demonstrations
selected_turns = select_turns_and_candidates_for_prompts(
    demos=demos,
    candidates=candidates,
    num_candidates=10,
)

# Build input records for training the model
input_records = build_input_records_from_selected_turns(
    selected_turns=selected_turns,
    format_intent=format_intent,
    build_prompt_records_fn=build_prompt_records_custom,
    format_prompt_records_fn=format_prompt_custom,
)
```
